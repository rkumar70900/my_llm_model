{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fd51261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a2d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local model running using llama.cpp server (quantized model)\n",
    "local_url = \"http://127.0.0.1:8034/v1/chat/completions\"\n",
    "\n",
    "# api model\n",
    "OPENAI_API_KEY = \"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\"\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddc6e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logprobs_text_from_local_model(local_url, prompt):\n",
    "    data = {\n",
    "        \"model\": \"Qwen3-VL-4B-Instruct-GGUF:Q4_K_M\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"logprobs\": 1\n",
    "    }\n",
    "\n",
    "    response = requests.post(local_url, json=data)\n",
    "    # logprobs = response.json()[\"choices\"][0][\"logprobs\"]['content']\n",
    "    # text = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25aa8e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_texts = [\n",
    "    \"Write a short fantasy story about a dragon and a wizard.\",\n",
    "    \"Explain quantum computing in simple terms.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcb1c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_openai_api(client, prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1f951d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_text_from_openai_api(client, prompt_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccafba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_logprobs_text_from_local_model(local_url, prompt_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb0d6649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def pdf_to_text(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "pdf_text = pdf_to_text(\"./test_pdf.pdf\")\n",
    "prompt_pdf = f\"Answer questions about this PDF:\\n{pdf_text}\\nQ: Summarize key points.\"\n",
    "# Then pass prompt_pdf to both model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d03277fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_logprobs_text_from_local_model(local_url, prompt_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "308c01ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here‚Äôs a concise summary of the key points from Rajesh Kumar Bandaru‚Äôs Statement of Purpose for a PhD in Computer Science:\\n\\n---\\n\\n**1. Core Interest & Motivation**  \\n- Believes AI models should be **runnable locally** (especially on edge devices with limited hardware).  \\n- First encountered the challenge of running large open-source models locally ‚Üí sparked interest in **quantization** as the most impactful technique for reducing memory, computation, and inference cost while preserving accuracy.\\n\\n**2. Technical Focus: Quantization Techniques**  \\n- Studied data types (integer vs. float), and advanced quantization methods: **GPTQ, AWQ, QLoRA**.  \\n- Authored technical articles:  \\n  - *‚ÄúHow Does Matrix Multiplication Happen in LLMs?‚Äù* ‚Äî on LLM internals and inference trade-offs.  \\n  - *‚ÄúMaking LLMs Smaller: The Story of Gpace* ‚Äî on post-training quantization techniques (lazy batch updates, Cholesky decomposition).  \\n- Built **GGUF Model Explorer** to inspect and understand quantized model metadata and storage.\\n\\n**3. Academic Background**  \\n- Master‚Äôs in Computer Science (Specialization: Computational Intelligence) ‚Äî focused on machine learning, deep learning, optimization, and algorithmic problem-solving.  \\n- Hands-on project: Built a **decoder-based transformer LLM from scratch** using PyTorch, exploring attention mechanisms and matrix operations.\\n\\n**4. Edge AI & Robotics Experience**  \\n- Built a **3D-printed robotic arm** with Raspberry Pi, camera, and Hailo AI module ‚Äî deployed lightweight object detection for edge inference.  \\n- Explored **robotics + AI integration**, emphasizing practical deployment.\\n\\n**5. Professional Experience**  \\n- **Data Automation Engineer**: Engineered end-to-end automation workflows using Python, Playwright, Azure ‚Äî automating ETL, Jira‚Üíjob conversion, and containerized deployments.  \\n- Strengthened skills in **reliable, hands-free system design** ‚Äî directly applicable to edge AI deployment pipelines.\\n\\n**6. Alignment with PhD Program**  \\n- Strongly aligned with the lab‚Äôs research in:  \\n  - **Efficient & Secure Machine Learning**  \\n  - **Edge AI**  \\n  - **Adaptive and secure AI deployment on edge devices**  \\n- Prior work in LLMs, robotics, and low-resource systems provides a solid foundation to contribute.\\n\\n**7. Future Research Goals**  \\n- Host a quantized QWEN model locally via llama.cpp ‚Üí compare performance with API-based models (ChatGPT, Claude, Gemini) across text, multi-modal, and PDF QA tasks.  \\n- Experiment with tokenization, hyperparameters, and **custom GPU kernels/inference engines** for real-time deployment.  \\n- Long-term: Explore **domain adaptation, 3D-vision, and edge AI holistically** ‚Äî developing lightweight, adaptable models for dynamic environments.\\n\\n**8. Personal Traits & Approach**  \\n- Highly **self-motivated, curious, and hands-on**.  \\n- Learns by **building and testing**, with a disciplined schedule.  \\n- Eager to bring this mindset to the lab, bridging theory and practical deployment of efficient, secure AI systems.\\n\\n---\\n\\n**In short**: Rajesh is driven by the goal of making AI models deployable on edge devices through advanced quantization and efficient inference. His blend of academic rigor, hands-on projects, robotics, and professional automation experience positions him to contribute meaningfully to research in efficient, secure, and adaptive edge AI ‚Äî especially in the context of decentralized systems.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be9054d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "image_base64 = image_to_base64(\"./test_image.jpeg\")\n",
    "prompt_image = f\"Answer the following about this image: ./test_image.jpeg (image data in base64: {image_base64})\"\n",
    "# Then pass prompt_image to both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa0aa502",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_logprobs_text_from_local_model(local_url, \"Who won the Nobel Peace Prize in 2026?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86e2a817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of now (April 2024), **there is no Nobel Peace Prize winner for 2026**, because the **Nobel Peace Prize is awarded annually, but not yet for the year 2026**.\\n\\nThe Nobel Prizes are awarded each year in **October**, and the **2026 Nobel Peace Prize** will be announced in **October 2026** ‚Äî which is still **over 2 years away**.\\n\\n**Important Note**: The Nobel Peace Prize is awarded by the **Norwegian Nobel Committee**, and the recipients are selected by a committee of five members (appointed by the Norwegian Parliament) and a jury of experts, based on recommendations from various countries and organizations.\\n\\n**Who might be candidates?**\\n\\nWhile no one has been officially named yet, potential candidates for the 2026 prize may include:\\n\\n- Leaders or organizations working for global peace, such as in conflict resolution, disarmament, or human rights.\\n- Activists or diplomats promoting international cooperation.\\n- Individuals or groups recognized for their efforts to reduce nuclear weapons, combat climate change, or protect vulnerable populations.\\n\\nBut ‚Äî **no one has been chosen or announced yet**.\\n\\nSo, to answer your question directly:\\n\\n> **There is no Nobel Peace Prize winner for 2026 yet, because it has not been awarded.**\\n\\nThe next Nobel Peace Prize will be awarded in **October 2026**, and the recipient will be announced in **late October or early November 2026**.\\n\\nLet me know if you‚Äôd like to know who won the Nobel Peace Prize in **2023**, **2024**, or any other recent year ‚Äî I can give you that too!\\n\\n---\\n\\n‚úÖ *Note: The Nobel Prizes are awarded in 1901 and continue to be given annually, so 2026 is still in the future ‚Äî it‚Äôs not a ‚Äúfake‚Äù or ‚Äúhypothetical‚Äù year. The Nobel Peace Prize will be awarded in 2026, just not yet.*'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bab486b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_logprobs_text_from_local_model(local_url, prompt_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32e5dc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': {'code': 400,\n",
       "  'message': 'the request exceeds the available context size, try increasing it',\n",
       "  'type': 'exceed_context_size_error',\n",
       "  'n_prompt_tokens': 223176,\n",
       "  'n_ctx': 20224}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d6aee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity_llama_format(logprobs):\n",
    "    token_logprobs = [tok['logprob'] for tok in logprobs if 'logprob' in tok]\n",
    "    \n",
    "    if not token_logprobs:\n",
    "        return None\n",
    "    \n",
    "    mean_logprob = np.mean(token_logprobs)\n",
    "    perplexity = np.exp(-mean_logprob)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1d06013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    if text is None:\n",
    "        text = \"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        text = \"empty\"\n",
    "    if len(text) > 8000:\n",
    "        text = text[:8000]\n",
    "    try:\n",
    "        res = client.embeddings.create(model=\"text-embedding-3-small\", input=text)\n",
    "        return np.array(res.data[0].embedding)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting embedding for text: {e}\")\n",
    "        return np.zeros(1536) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eb72040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(a, b):\n",
    "    return cosine_similarity([a], [b])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b840be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_text = []\n",
    "\n",
    "for prompt in prompt_texts:\n",
    "    qwen_logprobs, qwen_text = get_logprobs_text_from_local_model(local_url, prompt)\n",
    "    gpt4_text = get_text_from_openai_api(client, prompt)\n",
    "\n",
    "    perplexity_qwen = compute_perplexity_llama_format(qwen_logprobs)\n",
    "    sim_qwen = cosine_sim(get_embedding(prompt), get_embedding(qwen_text))\n",
    "    sim_gpt4 = cosine_sim(get_embedding(prompt), get_embedding(gpt4_text))\n",
    "\n",
    "    results_text.append({\n",
    "        \"prompt\": prompt,\n",
    "        \"qwen_text\": qwen_text,\n",
    "        \"gpt4_text\": gpt4_text,\n",
    "        \"perplexity_qwen\": perplexity_qwen,\n",
    "        \"sim_qwen\": sim_qwen,\n",
    "        \"sim_gpt4\": sim_gpt4\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "405c569a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'Write a short fantasy story about a dragon and a wizard.',\n",
       "  'qwen_text': '**The Dragon and the Wizard**\\n\\nIn the mist-shrouded kingdom of Eldermere, where ancient trees whispered secrets to the wind and rivers sang lullabies to the stars, there lived a wizard named Elion. He was known for his silver hair, his ever-open books, and his uncanny ability to summon storms from mere gestures. But Elion was not a man of power‚Äîhe was a man of patience, of quiet wisdom, of quiet courage.\\n\\nOne autumn evening, as the last golden leaves drifted to the earth, Elion wandered to the Whispering Peaks, where the legends spoke of a dragon named Veyra. Veyra was no ordinary beast. She was said to be the last of her kind‚Äîa fire-wreathed guardian whose breath could melt mountains, whose eyes held the sky‚Äôs sorrow.\\n\\nElion had come to seek her, not to conquer, but to understand. He believed dragons were more than myth, more than fire and fury. He thought they were the keepers of forgotten truths.\\n\\nHe climbed the jagged ridge, his boots crunching on brittle moss, and found her perched atop a crumbling spire of obsidian. Her scales glowed like molten amber, her wings, folded like ancient banners, shimmered with twilight hues. And her eyes‚Äîdeep, ancient, and full of questions.\\n\\n‚ÄúYou are the wizard who seeks the dragon,‚Äù she said, her voice like wind chimes in a storm. ‚ÄúWhy?‚Äù\\n\\nElion smiled, though his eyes held a tremor. ‚ÄúBecause I believe dragons are more than fire. I believe they are the keepers of stories. And stories, Veyra‚Ä¶ they‚Äôre fading.‚Äù\\n\\nVeyra tilted her head. ‚ÄúFading? From what?‚Äù\\n\\n‚ÄúThe magic of the world,‚Äù Elion whispered. ‚ÄúIt‚Äôs weakening. The old songs, the old spells, the old truths‚Ä¶ they‚Äôre slipping through our fingers like sand.‚Äù\\n\\nVeyra let out a long, slow sigh‚Äîa sound like a thousand rivers slowing their pace. ‚ÄúYou seek me. But I seek you.‚Äù\\n\\nElion knelt, offering a small vial of starlit water, the very essence of the sky‚Äôs memory. ‚ÄúI offer this. I offer my silence. I offer my questions.‚Äù\\n\\nShe drank it. And in that moment, the world trembled‚Äînot with fire, but with memory. The ancient forests, the lost cities, the names of forgotten kings‚Äîeach whispered back to them.\\n\\n‚ÄúMagic is not power,‚Äù Veyra said, her voice now softer, warmer, like the first rays of dawn. ‚ÄúIt is listening. It is remembering. It is choosing to believe.‚Äù\\n\\nElion stood. He turned to the horizon, where the sun dipped behind mountains of time.\\n\\n‚ÄúYou are not my enemy,‚Äù he said. ‚ÄúYou are my teacher.‚Äù\\n\\nAnd so, the wizard and the dragon walked side by side, not to conquer the world, but to remember it.\\n\\nThey became guardians of the stories‚Äîthe ones that had been lost, the ones that still lived, the ones that would be told, again, and again.\\n\\nAnd for centuries, the kingdom of Eldermere would be woven with the songs of a dragon and a wizard, who had learned that the greatest magic was not in fire, but in trust.\\n\\n‚Äî**The End‚Äî**\\n\\n*(And the story? It‚Äôs still being told.)*',\n",
       "  'gpt4_text': \"In the mystical land of Arindor, there lived a powerful wizard named Eridor and a fearsome dragon known as Drakon. Despite their differing natures, the two had formed an unlikely friendship that had endured for many years.\\n\\nEridor had saved Drakon from a group of dragon hunters who sought to slay him for his valuable scales, while Drakon had assisted Eridor in fending off dark creatures that threatened the land. Together, they had become a formidable duo, feared and respected by all who knew of their alliance.\\n\\nOne day, a dark sorcerer known as Malakar arrived in Arindor, seeking to overthrow the kingdom and plunge it into darkness. Eridor and Drakon knew they had to act quickly to stop him, for Malakar's powers were great and his army of dark creatures was vast.\\n\\nAs they prepared for battle, Eridor enchanted Drakon with a powerful spell that enhanced his already formidable strength and abilities. Drakon, now imbued with magical energy, soared into the sky and unleashed a torrent of flames upon Malakar's army, decimating their ranks with ease.\\n\\nMeanwhile, Eridor used his mastery of elemental magic to bind Malakar in chains of pure energy, rendering him powerless to wield his dark sorcery. Together, the wizard and the dragon fought back the forces of darkness, driving Malakar and his minions from Arindor once and for all.\\n\\nIn the aftermath of the battle, Eridor and Drakon stood victorious, their bond stronger than ever. The people of Arindor hailed them as heroes, grateful for their courage and sacrifice in protecting their land.\\n\\nAnd so, the wizard and the dragon continued to roam the wilds of Arindor, their friendship enduring for eternity as they fought alongside each other, defending the realm from all who dared to threaten its peace.\",\n",
       "  'perplexity_qwen': np.float64(2.1539203899182415),\n",
       "  'sim_qwen': np.float64(0.572340351065041),\n",
       "  'sim_gpt4': np.float64(0.5393837539260271)},\n",
       " {'prompt': 'Explain quantum computing in simple terms.',\n",
       "  'qwen_text': 'Sure! Let‚Äôs break it down in simple terms.\\n\\n---\\n\\n**Imagine you have a regular computer ‚Äî like the one you use to browse the web or watch videos.**\\n\\nIt uses **bits** ‚Äî tiny switches that can be either **0 or 1**. Think of them like light switches: off (0) or on (1).\\n\\nThat‚Äôs how regular computers work ‚Äî they do everything by turning bits on and off in different combinations.\\n\\n---\\n\\n**Now imagine a ‚Äúquantum computer‚Äù ‚Äî which uses something called ‚Äúqubits.‚Äù**\\n\\nQubits are like bits, but they can be **0, 1, or both at the same time** ‚Äî kind of like a coin that‚Äôs spinning in the air, not yet landed. This is called **superposition**.\\n\\nAlso, qubits can be ‚Äútied together‚Äù ‚Äî like two coins that are always the same (if you flip them together, they both land heads or both tails). This is called **entanglement**.\\n\\n---\\n\\n**Why does this matter?**\\n\\nBecause of these weird quantum rules, a quantum computer can try **many possible answers at once** ‚Äî like a super-powered guesser. That‚Äôs super useful for solving problems that would take normal computers forever.\\n\\nFor example:\\n- Simulating molecules (for new medicines)\\n- Optimizing delivery routes\\n- Breaking certain types of encryption (also, which is good to know for security!)\\n\\n---\\n\\n**But here‚Äôs the catch:**\\n\\nQuantum computers are still very new and tricky. They need to be kept super cold (near absolute zero), protected from noise, and are still not as powerful as regular computers for everyday tasks.\\n\\n---\\n\\n**TL;DR:**\\n\\n> A quantum computer uses qubits that can be 0, 1, or both at once ‚Äî and can ‚Äúcommunicate‚Äù with each other. This lets them solve some super hard problems much faster than regular computers ‚Äî but they‚Äôre not ready to replace our daily gadgets yet.\\n\\n---\\n\\nThink of it like a magic calculator that can try lots of answers at once, thanks to the weird rules of the quantum world. üåå\\n\\nLet me know if you want to dive deeper into any part!',\n",
       "  'gpt4_text': 'Quantum computing is a type of computing that uses principles of quantum mechanics to perform calculations. In traditional computers, information is processed in binary code, represented by either 0 or 1. However, in a quantum computer, information is stored in quantum bits, or qubits, which can represent 0, 1, or both at the same time.\\n\\nThis ability to be in multiple states at once allows quantum computers to perform calculations much faster than traditional computers. They can solve complex problems in a fraction of the time it would take a classical computer to do so.\\n\\nIn essence, quantum computing harnesses the unique properties of quantum mechanics to process and analyze information in a fundamentally different way from classical computers, leading to faster and more efficient calculations.',\n",
       "  'perplexity_qwen': np.float64(1.388822476340396),\n",
       "  'sim_qwen': np.float64(0.634610748889022),\n",
       "  'sim_gpt4': np.float64(0.7069464016670535)}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234f62e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
